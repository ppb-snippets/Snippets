{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Typical machine learning usage\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer as dv\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap as lcmap\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from io import StringIO\n",
    "# from sklearn.externals.six import StringIO as StrIO\n",
    "from StringIO import StringIO as StrIO\n",
    "from subprocess import check_call\n",
    "import pydotplus as pydot\n",
    "\n",
    "import graphviz as gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   2. ,   3. ,   4. ],\n",
       "       [  5. ,   6. ,   7.5,   8. ],\n",
       "       [ 10. ,  11. ,  12. ,   6. ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing - imputation\n",
    "csv_data = \"\"\"A,B,C,D\n",
    "1.0, 2.0, 3.0, 4.0\n",
    "5.0, 6.0,, 8.0\n",
    "10.0, 11.0, 12.0,\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(unicode(csv_data)))\n",
    "df\n",
    "\n",
    "imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing - normalization\n",
    "iris = datasets.load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "X, y = X_iris[:, :2], y_iris\n",
    "X_train, X_test, y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing - sklearn.feature_extraction.DictVectorizer, transform feature-value mappings to \n",
    "# vectors.\n",
    "iris = datasets.load_iris()\n",
    "y = iris.target\n",
    "iris_dv = dv(sparse=False)\n",
    "my_dict = [{'species': iris.target_names[i]} for i in y]\n",
    "my_dict_trans = iris_dv.fit_transform(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "boston = datasets.load_boston()\n",
    "boston_X = boston.data\n",
    "boston_y = boston.target\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(boston_X, boston_y)\n",
    "predictions = lr.predict(boston_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clustering - KMeans\n",
    "blobs, ground_truth = datasets.make_blobs(1000, centers=3, cluster_std=1.75)\n",
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "kmeans.fit(blobs)\n",
    "for i in range(3): # estimate accuracy of each cluster\n",
    "    print (kmeans.labels_==ground_truth)[ground_truth==i].astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decision tree, function for plotting decision regions\n",
    "def plot_decision_regions (X, y, classifier, test_idx, resolution=0.02):\n",
    "    \n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = lcmap(colors[:len(np.unique(y))])\n",
    "\n",
    "    x1_min, x1_max = X[:, 0].min()-1, X[:, 0].max()+1\n",
    "    x2_min, x2_max = X[:, 1].min()-1, X[:, 1].max()+1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), \n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    \n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y==cl,0], y=X[y==cl,1], alpha=0.8,\n",
    "                   c=cmap(idx), marker=markers[idx], label=cl)\n",
    "     \n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        plt.scatter(X_test[:,0], X_test[:,1], c='', alpha=1.0, linewidth=1,\n",
    "                   marker='o', s=55, label='test set')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decision tree, plot decision regions\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2,3]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='entropyc', max_depth=3,\n",
    "                           max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
    "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                           presort=False, random_state=0, splitter='best')\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "plot_decision_regions(X_combined, y_combined, classifier=dt,\n",
    "                     test_idx=range(105, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decision tree, visualize\n",
    "\n",
    "# #convert dot to image format, method 1\n",
    "# export_graphviz(dt, out_file='tree.dot', feature_names =['petal length', 'petal width'])\n",
    "# check_call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png'])\n",
    "\n",
    "#convert dot to image format, method 2  \n",
    "str_buffer = StrIO()\n",
    "export_graphviz(dt, out_file=str_buffer, feature_names =['petal length', 'petal width'])\n",
    "graph = pydot.graph_from_dot_data(str_buffer.getvalue())\n",
    "graph.write_png('tree.png')\n",
    "\n",
    "img = mpimg.imread('tree.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest, prediction\n",
    "X, y = datasets.make_classification(1000)\n",
    "rf = RFC()\n",
    "rf.fit(X, y)\n",
    "\n",
    "probs = rf.predict_proba(X)\n",
    "probs_df = pd.DataFrame(probs, columns = ['0', '1'])\n",
    "probs_df['was_correct'] = rf.predict(X) == y\n",
    "\n",
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "probs_df.groupby('0').was_correct.mean().plot(kind='bar', ax=ax)\n",
    "ax.set_title('Accuracy at 0 class probability')\n",
    "ax.set_ylabel('% Correct')\n",
    "ax.set_xlabel('% trees for 0')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest, confusion matrix\n",
    "X, y = datasets.make_classification(n_samples=10000,\n",
    "                                    n_features=20,\n",
    "                                    n_informative=15,\n",
    "                                    flip_y=0.5, weights=[0.2, 0.8])\n",
    "training = np.random.choice([True, False], p=[0.8, 0.2],\n",
    "                            size=y.shape)\n",
    "max_feature_params = ['auto', 'sqrt', 'log2', 0.01, 0.5, 0.99]\n",
    "confusion_matrixes = {}\n",
    "\n",
    "for max_feature in max_feature_params:\n",
    "    rf = RFC(max_features=max_feature)\n",
    "    rf.fit(X[training], y[training])\n",
    "    confusion_matrixes[max_feature] = confusion_matrix(y[~training], rf.predict(X[~training])).ravel()\n",
    "#     confusion_matrixes[max_feature] = confusion_matrix(y[~training], rf.predict(X[~training]))\n",
    "confusion_df = pd.DataFrame(confusion_matrixes)\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(7,5))    \n",
    "confusion_df.plot(kind='bar', ax=ax)   \n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.grid()\n",
    "ax.set_xticklabels([str((i, j)) for i, j in \n",
    "                   list(itertools.product(range(2), range(2)))])\n",
    "\n",
    "    \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian process\n",
    "boston = datasets.load_boston()\n",
    "boston_X = boston.data\n",
    "boston_y = boston.target\n",
    "\n",
    "train_set = np.random.choice([True, False], len(boston_y), [0.75, 0.25])\n",
    "gp = GaussianProcess()\n",
    "gp.fit(boston_X[train_set], boston_y[train_set])\n",
    "test_preds = gp.predict(boston_X[~train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode categorial values with LabelEncoder and OneHotEncoder\n",
    "X_train = pd.read_csv('../loan_prediction-1/X_train.csv')\n",
    "Y_train = pd.read_csv('../loan_prediction-1/Y_train.csv')\n",
    "X_test = pd.read_csv('../loan_prediction-1/X_test.csv')\n",
    "Y_test = pd.read_csv('../loan_prediction-1/Y_test.csv')\n",
    "\n",
    "# LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in X_test.columns.values:\n",
    "    if X_test[col].dtypes=='object':\n",
    "        data = X_train[col].append(X_test[col])\n",
    "        le.fit(data.values)\n",
    "        X_train[col] = le.transform(X_train[col])\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "# OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "X_train_1 = X_train\n",
    "X_test_1 = X_test\n",
    "columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
    "          'Credit_History', 'Property_Area']\n",
    "for col in columns:\n",
    "    data = pd.DataFrame(X_train[col].append(X_test[col]))\n",
    "    enc.fit(data.values.reshape(-1,1))\n",
    "    temp = enc.transform(X_train[col].values.reshape(-1,1))\n",
    "    temp = pd.DataFrame(temp, columns = [(col+\"_\"+str(i)) for i in data[col].value_counts().index])\n",
    "    temp = temp.set_index(X_train.index.values)\n",
    "    X_train_1 = pd.concat([X_train_1, temp], axis=1)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# practice...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "col1, col2, col3\n",
    "1, st1, 2.0\n",
    "3, st2, 5.0\n",
    "2, st2, 3.0\n",
    "5, st1, 6.0\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(unicode(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
